{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3b00304-65c5-4957-b820-b1e46cc15ea7",
   "metadata": {},
   "source": [
    "## Course Assignment Instructions\n",
    "You should have Python (version 3.8 or later) and Jupyter Notebook installed to complete this assignment. You will write code in the empty cell/cells below the problem. While most of this will be a programming assignment, some questions will ask you to \"write a few sentences\" in markdown cells. \n",
    "\n",
    "Submission Instructions:\n",
    "\n",
    "Create a labs directory in your personal class repository (e.g., located in your home directory)\n",
    "Clone the class repository\n",
    "Copy this Jupyter notebook file (.ipynb) into your repo/labs directory\n",
    "Make your edits, commit changes, and push to your repository\n",
    "All submissions must be pushed before the due date to avoid late penalties. \n",
    "\n",
    "Labs are graded out of a 100 pts. Each day late is -10. For a max penalty of -50 after 5 days. From there you may submit the lab anytime before the semester ends for a max score of 50.  \n",
    "\n",
    "Lab 6 is due on 3/24/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed64cc-890e-43f2-a406-1b0a63e0ba51",
   "metadata": {},
   "source": [
    "#Visualization in Python\n",
    "\n",
    "Load up the `GSSvocab.csv` dataset into a pandas dataframe and and drop the rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11544058-d49f-48ac-94d6-0d100ed34e10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31bc67e9-46ff-4722-851f-f40552fa86e2",
   "metadata": {},
   "source": [
    "What is the data type of each variable? What do you think is the response variable the collectors of this data had in mind?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a182eb9c-80e2-4ea8-a3aa-076b88e363ed",
   "metadata": {},
   "source": [
    "There are 8 variables: year, gender, nativeBorn, ageGroup, educGroup, vocab, age, and educ.\n",
    "Year, gender, nativeBorn, ageGroup, eduGroup, educ are categorical variables.\n",
    "Age and education are continuous variables.\n",
    "The response variable I think was to see what features correlated with a higher vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb5be8-e9ab-44c2-90b7-c763679d0f73",
   "metadata": {},
   "source": [
    "Create two different plots and identify the best-looking plot you can to examine the `age` variable. Save the best looking plot as an appropriately-named PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07a5464-a7c5-43f7-8c6c-c6c0170f6a50",
   "metadata": {},
   "source": [
    "Using plotnine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bece01-c755-48c5-981e-458ef0481b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import ggplot, aes, geom_histogram, geom_density, labs, ggsave\n",
    "\n",
    "# Plot 1: Histogram of age with 50 bins\n",
    "hist_plot = (\n",
    "    ggplot(df, aes(x='age')) +\n",
    "    geom_histogram(bins=50) +\n",
    "    labs(x='Age', y='Frequency', title='Histogram of Age')\n",
    ")\n",
    "\n",
    "# Plot 2: Density plot of age with blue fill\n",
    "density_plot = (\n",
    "    \n",
    ")\n",
    "\n",
    "# Display the plots (if using an interactive environment, they will be rendered)\n",
    "hist_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72737386-bcc3-4cfa-b88d-eb2da0d3fb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27a3ba63-84d2-41fd-9fcf-32ef54047a4e",
   "metadata": {},
   "source": [
    "Using Seaborn and Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fe74fd-dd49-45f2-8773-a90b6176ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf05354c-dc28-457f-a690-eed39ca099df",
   "metadata": {},
   "source": [
    "We will use plotninem (https://plotnine.org/) as our visualization tool for the first half of this lab. Create two different plots and identify the best looking plot you can to examine the `vocab` variable. Save the best looking plot as an appropriately-named PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd509df-5612-416d-8d33-0436e2614994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import ggplot, aes, geom_bar, geom_point, labs, theme_minimal, ggsave, position_jitter\n",
    "\n",
    "# Assume df is your GSSvocab DataFrame\n",
    "# Ensure that vocab is treated as a categorical variable\n",
    "\n",
    "# ---- Plot 1: Bar Plot ----\n",
    "bar_plot = (ggplot(df, aes(x='vocab')) +\n",
    "            \n",
    "\n",
    "\n",
    "# Display the plots (in an interactive environment, these will render)\n",
    "print(bar_plot)\n",
    "bar_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69589487-77c2-4fef-b937-dd646bbc28e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a jitter plot for 'vocab'\n",
    "\n",
    "\n",
    "jitter_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7217808b-2ca5-4b95-990e-3ff4171e6d6b",
   "metadata": {},
   "source": [
    "Create the best-looking plot you can to examine the `ageGroup` variable by `gender`. Does there appear to be an association? There are many ways to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09147d86-1312-4f16-aacc-008483c33e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from plotnine import ggplot, aes, geom_violin, labs, theme_minimal\n",
    "\n",
    "# Assume df is your DataFrame containing the columns 'ageGroup' and 'gender'.\n",
    "# Make sure 'gender' is treated as a categorical variable:\n",
    "\n",
    "\n",
    "# Create a violin plot by switching the axes:\n",
    "\n",
    "\n",
    "violin_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5115271-f3cd-4507-8dd8-c194c79cae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from plotnine import ggplot, aes, geom_jitter, labs, theme_minimal\n",
    "\n",
    "# Assume df is your DataFrame containing the columns 'ageGroup' and 'gender'\n",
    "# Ensure 'gender' is treated as a categorical variable\n",
    "df['gender'] = df['gender'].astype('category')\n",
    "\n",
    "\n",
    "\n",
    "jitter_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25988f40-d1bc-4732-97fa-b2027041d546",
   "metadata": {},
   "source": [
    "Create the best-looking plot you can to examine the `vocab` variable by `age`. Does there appear to be an association?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e3f398-ec6f-4e40-bd7f-bffaea09844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from plotnine import ggplot, aes, geom_jitter, labs, theme_minimal\n",
    "\n",
    "# Create a jitter plot to examine the relationship between age and vocab\n",
    "plot = (ggplot()) +\n",
    "        geom_jitter() +\n",
    "        \n",
    "        theme_minimal())\n",
    "\n",
    "plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac807fd-0c10-45c0-9701-c1cde7ad4571",
   "metadata": {},
   "source": [
    "Add an estimate of $f(x)$ using the smoothing geometry to the previous plot. Does there appear to be an association now? First install pygam by uncommenting and running the cell below and then fill in the missing block in the subsequent cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a50b83c-2991-4f83-b07b-ebf038a61a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pygam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a59fe1-e3aa-43c8-8b89-3e408f1cf5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pygam import LinearGAM, s\n",
    "from plotnine import ggplot, aes, geom_point, geom_line, labs, theme_minimal, scale_y_continuous\n",
    "\n",
    "# Assume df is your DataFrame with 'age' and 'vocab' columns.\n",
    "# Ensure 'vocab' is numeric (if it's not already)\n",
    "df['vocab'] = pd.to_numeric(df['vocab'], errors='coerce')\n",
    "\n",
    "# Fit a GAM model for vocab ~ s(age)\n",
    "X = df[['age']].values  \n",
    "y = df['vocab'].values\n",
    "gam = LinearGAM(s(0)).fit(X, y)\n",
    "\n",
    "# Create a grid of age values for prediction\n",
    "age_grid = np.linspace(df['age'].min(), df['age'].max(), 100)\n",
    "gam_preds = gam.predict(age_grid)\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "gam_df = pd.DataFrame({\n",
    "    'age': age_grid,\n",
    "    'vocab': gam_preds\n",
    "})\n",
    "\n",
    "# Create the plot with y-axis limits between 4.8 and 6.8\n",
    "plot = ()\n",
    "\n",
    "plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205018ba-9b7b-4f5f-b4e7-5fac576c59b4",
   "metadata": {},
   "source": [
    "Using the plot from the previous question, create the best looking plot overloading with variable `gender`. Does there appear to be an interaction of `gender` and `age`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500ea766-ec8d-4483-9128-dfa47b91ac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import ggplot, aes, geom_jitter, geom_smooth, labs, theme_minimal\n",
    "\n",
    "# Assume df is your DataFrame containing 'age', 'vocab', and 'gender'\n",
    "# For example, df = pd.read_csv(\"GSSvocab.csv\")\n",
    "\n",
    "\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cb5a21-f59a-4969-89bd-5165187e8f6c",
   "metadata": {},
   "source": [
    "Using the plot from the previous question, create the best looking plot overloading with variable `nativeBorn`. Does there appear to be an interaction of `nativeBorn` and `age`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26f9954-aeff-48a2-9337-6edfc45d09d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import ggplot, aes, geom_jitter, geom_smooth, labs, theme_minimal\n",
    "\n",
    "# Assume df is your GSSvocab DataFrame containing 'age', 'vocab', and 'nativeBorn'\n",
    "\n",
    "plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e3ed31-a719-4ca7-9e75-bcdc121c3a7d",
   "metadata": {},
   "source": [
    "Create two different plots and identify the best-looking plot you can to examine the `vocab` variable by `educGroup`. Does there appear to be an association?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba963397-9a4f-47db-8b78-2c277e741ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from plotnine import ggplot, aes, geom_boxplot, geom_density, labs, theme_minimal\n",
    "\n",
    "# Assume df is your GSSvocab DataFrame containing the columns 'vocab' and 'educGroup'\n",
    "# Ensure that 'educGroup' is treated as a categorical variable\n",
    "df['educGroup'] = df[].astype('category')\n",
    "\n",
    "# ---- Plot 1: Boxplot of vocab by educGroup ----\n",
    "boxplot = (ggplot(df, aes(x='educGroup', y='vocab')) +\n",
    "           geom_boxplot() +\n",
    "          \n",
    "boxplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bb82b8-09ed-4e8d-8118-e09d5c8c8178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Plot 2: Density Plot of vocab with fill by educGroup ----\n",
    "\n",
    "density_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547dc79b-81fa-4cf4-bcf3-b0cde5e89ae3",
   "metadata": {},
   "source": [
    "Using the best-looking plot from the previous question, create the best looking overloading with variable `gender`. Does there appear to be an interaction of `gender` and `educGroup`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b6bb5b-91ae-4d50-bbd9-8399d5aced12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c5bf879-e91c-4be3-9563-372617a2cbe1",
   "metadata": {},
   "source": [
    "Using facets, examine the relationship between `vocab` and `ageGroup`. You can drop year level `(Other)`. Are we getting dumber?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7049e0ce-6f73-464f-b202-0957798d6097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from plotnine import ggplot, aes, geom_density, facet_grid, labs, theme_minimal\n",
    "\n",
    "# Assume df is your GSSvocab DataFrame.\n",
    "# Drop the unwanted level \"(Other)\" from ageGroup.\n",
    "df_subset = df[]\n",
    "\n",
    "# Create the density plot faceted by ageGroup.\n",
    "\n",
    "\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8d0048-6927-4f25-aa2a-67c94ecfdcfa",
   "metadata": {},
   "source": [
    "#Logistic Regression\n",
    "\n",
    "Let's consider the Pima Indians Diabetes dataset from 1988:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5208e1-ea53-43ca-9b96-3886908c7291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the Pima.tr2 dataset from the MASS package\n",
    "pima_dataset = sm.datasets.get_rdataset(\"Pima.tr2\", package=\"MASS\")\n",
    "df = pima_dataset.data\n",
    "\n",
    "# Display the first few rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18801811-6f9a-4012-9f59-a267c65d689e",
   "metadata": {},
   "source": [
    "Note the missing data. We will learn about how to handle missing data towards the end of the course. For now, replace, the missing data in the design matrix X with the mean of the feature x_dot,j. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb208ad-4eb2-4247-babb-2421084dd90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the design matrix X with an intercept column \n",
    "\n",
    "\n",
    "# Replace missing values in each column with the mean of that column\n",
    "\n",
    "\n",
    "# Verify that missing values have been replaced\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abf4ad5-3fee-4492-878d-ddfb93140d7a",
   "metadata": {},
   "source": [
    "Now let's fit a log-odds linear model of y=1 (type is \"diabetic\") on just the `glu` variable. Import minimize from scipy.optimize to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e527a0ac-2b5c-4590-a7f3-eda98bca1650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "y = pima['type'].values\n",
    "X = pima['glu'].values\n",
    "\n",
    "# Define the negative log-likelihood function for logistic regression\n",
    "def neg_loglik(beta):\n",
    "  \n",
    "    return \n",
    "\n",
    "# Use minimize from SciPy to optimize the negative log-likelihood\n",
    "result = minimize()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769f0286-e0c3-470e-891d-942389d73d9b",
   "metadata": {},
   "source": [
    "Extra Credit(+5): write a `fit_logistic_regression` function which takes in X, y and returns b which uses the optimization routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d935c2-04ad-495d-adbb-cfedec1c1564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a57ebdc7-47cf-4771-83b4-228cdd2d9d8d",
   "metadata": {},
   "source": [
    "Run a logistic regression of y=1 (type is \"diabetic\") on just the `glu` variable using sm from statsmodels.api and report b_0, b_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6ea98a-5ab6-4d07-8a08-ccc53bb9bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Add a constant column for the intercept\n",
    "\n",
    "# Fit the logistic regression model using y as the response and glu as the predictor\n",
    "\n",
    "\n",
    "# Extract the coefficients: b0 (intercept) and b1 (for glu)\n",
    "coef = \n",
    "\n",
    "print(\"b0 (Intercept):\", )\n",
    "print(\"b1 (glu):\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abfcdb1-2984-49b9-86fd-6b4b17725681",
   "metadata": {},
   "source": [
    "Comment on how close the results from Statsmodels built in function was to your optimization call."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408c571b-6e63-4036-beb5-27e48f9d6eea",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5a58f06-f9b5-40f8-82b8-ba5bc141c032",
   "metadata": {},
   "source": [
    "Interpret the value of b_1 from Statsmodels smf module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2394fc9d-44de-49df-a5d7-d46b390571c0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67018523-3342-48b8-9988-ada47831c1d7",
   "metadata": {},
   "source": [
    "Interpret the value of b_0 from Statsmodels smf module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922e8a3b-36f1-4d7b-b6eb-fee309d2fe19",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b62b637-560f-4efc-b80d-46659de52046",
   "metadata": {},
   "source": [
    "Plot the probability of y=1 from the minimum value of `glu` to the maximum value of `glu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5362e1-43cf-4006-b5e4-df3ced89134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a new DataFrame with the glu values sorted from min to max\n",
    "\n",
    "\n",
    "# Add the constant column so that newdata matches the model's predictors\n",
    "\n",
    "\n",
    "# Compute the predicted probabilities for y = 1 using the fitted model\n",
    "\n",
    "\n",
    "# Plot the predicted probability curve \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1bdc2c-a47d-4124-ad74-54cb872cd956",
   "metadata": {},
   "source": [
    "Run a logistic regression of y=1 (type is \"diabetic\") on all variables using statsmodels sm module and report the b vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b7f230-b82d-47a9-a9b3-0f39480cab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab all the columns except 'type'\n",
    "X = pima.iloc[:,:8]\n",
    "\n",
    "# Fit the logistic regression model using y as the response and glu as the predictor\n",
    "model = sm.Logit(y, X).fit()\n",
    "\n",
    "# Report the estimated coefficients (b vector)\n",
    "print(\"Coefficient vector (b):\")\n",
    "print(model.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20237ade-053a-4e9a-93c7-585fbd796746",
   "metadata": {},
   "source": [
    "Predict the probability of diabetes for someone with a blood sugar of 150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16192f3a-5310-4ce4-81b9-a79f6cc09cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Compute means for the other variables\n",
    "\n",
    "\n",
    "# Create a new data point, using 150 for glu and the means for the others\n",
    "glu_150 = pd.DataFrame({\n",
    "    \n",
    "    'npreg': [predictor_means['npreg']],\n",
    "\n",
    "    'bp': [predictor_means['bp']],\n",
    "    'skin': [predictor_means['skin']],\n",
    "    'bmi': [predictor_means['bmi']],\n",
    "    'ped': [predictor_means['ped']],\n",
    "    'age': [predictor_means['age']]\n",
    "})\n",
    "\n",
    "# Predict using the fitted model\n",
    "\n",
    "print(\"Predicted probability of diabetes for blood sugar 150:\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a6dee7-0245-4083-af26-680f81c80b3c",
   "metadata": {},
   "source": [
    "For 100 people with blood sugar of 150, what is the probability more than 75 of them have diabetes? (You may need to review 241 to do this problem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8592bba6-63bb-4413-a2ee-9773fc69131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Compute the probability that more than 75 of them have diabetes.\n",
    "# This is: 1 - P(X <= 75)\n",
    "\n",
    "\n",
    "print(\"Probability that more than 75 out of 100 people have diabetes:\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2363904b-4564-4300-90d6-202fb7cf1fba",
   "metadata": {},
   "source": [
    "Plot the in-sample log-odds predictions (y-axis) versus the real response values (x-axis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f813c87b-e0dd-4d28-93cd-f0e49c349b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute the in-sample log-odds predictions (linear predictor)\n",
    "\n",
    "\n",
    "# Create a DataFrame that holds the real responses and the log-odds predictions\n",
    "df_plot = pd.DataFrame({\n",
    "    'Real_Response': y,           # actual binary response values (0 or 1)\n",
    "    'Predicted_LogOdds': log_odds_predictions\n",
    "})\n",
    "\n",
    "# Plot using seaborn's scatterplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=df_plot, x=, y=, color=)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.title(\"\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be0f24e-9aad-4e59-96dc-0d5f25b1b4b2",
   "metadata": {},
   "source": [
    "Plot the in-sample probability predictions (y-axis) versus the real response values (x-axis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90c3370-ec88-4f77-8aec-ebfd9ad8940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predicted probabilities using your fitted logistic regression model.\n",
    "# X is your original design matrix with the intercept\n",
    "\n",
    "# Create a DataFrame that holds the actual binary responses and the predicted probabilities.\n",
    "df_plot = pd.DataFrame({\n",
    "    'Real_Response': y,                 # Actual response values (0 or 1)\n",
    "    'Predicted_Probability': predicted_probs\n",
    "})\n",
    "\n",
    "# Plot using seaborn's scatterplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=df_plot, x='Real_Response', y='Predicted_Probability', color='blue')\n",
    "plt.xlabel()\n",
    "plt.ylabel()\n",
    "plt.title()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ee3a68-6ae7-4169-ad29-1f27863e77ac",
   "metadata": {},
   "source": [
    "Comment on how well you think the logistic regression performed in-sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faec200a-d980-4c9d-a56a-1e1f1f5a3508",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea0d727d-5c75-4530-96eb-20a557e9b82f",
   "metadata": {},
   "source": [
    "Calculate the in-sample Brier score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51638097-dd27-44d5-a376-73a7adabe8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compute the in-sample Brier score\n",
    "# Brier Score = (1/n) * sum( (y - predicted_prob)^2 )\n",
    "brier_score = np.mean(()\n",
    "\n",
    "print(\"In-sample Brier score:\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6089f6-4c8c-4d23-a4c2-57db2a08cfac",
   "metadata": {},
   "source": [
    "Calculate the in-sample log-scoring rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cd3720-d1bc-420d-a798-eadb19d33f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# To avoid taking log(0), add a small constant epsilon\n",
    "epsilon = 1e-9\n",
    "\n",
    "# Calculate the negative average log-likelihood\n",
    "# Also known as the log scoring rule\n",
    "log_score = -np.mean(\n",
    "    \n",
    ")\n",
    "\n",
    "print(\"In-sample log scoring rule:\", log_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9d9a8d-490c-4d81-b14a-84beaa34dbaa",
   "metadata": {},
   "source": [
    "Run a probit regression of y=1 (type is \"diabetic\") on all variables and report the b vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270fc412-24b5-4986-8167-290525032a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab all the columns except 'type'\n",
    "X = pima.iloc[:,:8]\n",
    "\n",
    "# Fit the probit regression model using sm.Probit\n",
    "model = \n",
    "\n",
    "# Report the estimated coefficient vector (b)\n",
    "print(\"Coefficient vector (b):\")\n",
    "print(model.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa1210e-a8c1-41a9-91be-5adeb664307c",
   "metadata": {},
   "source": [
    "Does the weight estimates here in the probit fit have different signs than the weight estimates in the logistic fit? What does that mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dec46fe-09a4-4e58-aa8e-9ddb66bcc5c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4eaabcb7-4f68-42b1-b112-eb131eaf123d",
   "metadata": {},
   "source": [
    "Plot the in-sample probability predictions (y-axis) versus the real response values (x-axis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c693ab6-b857-467b-b9c3-572ad88c0e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predicted probabilities using your fitted logistic regression model.\n",
    "probit_probs = model.predict(X)  # X is your original design matrix with the intercept\n",
    "\n",
    "# Create a DataFrame that holds the actual binary responses and the predicted probabilities.\n",
    "df_plot = pd.DataFrame({\n",
    "    'Real_Response': y,                 # Actual response values (0 or 1)\n",
    "    'Predicted_Probability': probit_probs\n",
    "})\n",
    "\n",
    "# Plot using seaborn's scatterplot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f59682-c4fc-4dfb-9727-d10d24ad1407",
   "metadata": {},
   "source": [
    "Calculate the in-sample Brier score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a8b126-d9c1-4726-945c-b7643cea8a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compute the in-sample Brier score\n",
    "# Brier Score = (1/n) * sum( (y - predicted_prob)^2 )\n",
    "Probit_brier_score = \n",
    "\n",
    "print(\"In-sample Brier score:\", Probit_brier_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603c4e3a-c7bb-4146-a3d8-4b5abc5ee33e",
   "metadata": {},
   "source": [
    "Calculate the in-sample log-scoring rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7359c3c-9c93-410f-be34-5de6cf5b1c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# To avoid taking log(0), add a small constant epsilon\n",
    "epsilon = 1e-9\n",
    "\n",
    "# Calculate the negative average log-likelihood\n",
    "# Also known as the log scoring rule\n",
    "Probit_log_score = -np.mean(\n",
    "   \n",
    ")\n",
    "\n",
    "print(\"In-sample log scoring rule:\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a6c51c-b2f3-4998-b1c3-b81e90105bd5",
   "metadata": {},
   "source": [
    "Which model did better in-sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88c0a39-eb42-4bca-b090-0b01fd7ccc57",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1443c08f-e7db-42d7-83cc-f39facf34f04",
   "metadata": {},
   "source": [
    "Compare both models oos using the Brier score and a test set with 1/3 of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2272ef-5de4-4434-a3cd-48df3afa23cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Grab all the columns except 'type'\n",
    "X = pima.iloc[:,:8]\n",
    "y = pima['type'].values\n",
    "\n",
    "# Split the data: 2/3 training, 1/3 test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=1/3, random_state=42\n",
    ")\n",
    "\n",
    "# Fit the logistic regression (logit) model on the training set\n",
    "\n",
    "\n",
    "# Fit the probit model on the training set\n",
    "\n",
    "\n",
    "# Predict probabilities on the test set for both models\n",
    "\n",
    "\n",
    "# Calculate the out-of-sample Brier score for each model\n",
    "# Brier Score = mean( (actual - predicted)^2 )\n",
    "\n",
    "\n",
    "print(\"Out-of-sample Brier Score (Logit):\", brier_logit)\n",
    "print(\"Out-of-sample Brier Score (Probit):\", brier_probit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db8acb0-d736-499d-9dda-c94e75d6a9a6",
   "metadata": {},
   "source": [
    "Which model did better oos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290d3bcb-430b-49d1-a121-d7064cf0a9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
